2019-08-15 12:32:34.970085 EDT | [rlkit-post-refactor-td3-half-cheetah_2019_08_15_12_32_20_0000--s-0] Epoch 0 finished
----------------------------------------------  --------------
replay_buffer/size                              2000
trainer/QF1 Loss                                   0.0169954
trainer/QF2 Loss                                   0.0167289
trainer/Policy Loss                                0.0311904
trainer/Q1 Predictions Mean                        0.00742701
trainer/Q1 Predictions Std                         0.00173556
trainer/Q1 Predictions Max                         0.0121705
trainer/Q1 Predictions Min                         0.00323448
trainer/Q2 Predictions Mean                        0.00316584
trainer/Q2 Predictions Std                         0.0014655
trainer/Q2 Predictions Max                         0.00701652
trainer/Q2 Predictions Min                        -0.000221426
trainer/Q Targets Mean                            -0.0114156
trainer/Q Targets Std                              0.128288
trainer/Q Targets Max                              0.358039
trainer/Q Targets Min                             -0.419912
trainer/Bellman Errors 1 Mean                      0.0169954
trainer/Bellman Errors 1 Std                       0.0255741
trainer/Bellman Errors 1 Max                       0.184498
trainer/Bellman Errors 1 Min                       1.05681e-08
trainer/Bellman Errors 2 Mean                      0.0167289
trainer/Bellman Errors 2 Std                       0.0250778
trainer/Bellman Errors 2 Max                       0.179923
trainer/Bellman Errors 2 Min                       2.55955e-09
trainer/Policy Action Mean                         0.00274454
trainer/Policy Action Std                          0.00537745
trainer/Policy Action Max                          0.0122428
trainer/Policy Action Min                         -0.00908939
exploration/num steps total                     2000
exploration/num paths total                        2
exploration/path length Mean                    1000
exploration/path length Std                        0
exploration/path length Max                     1000
exploration/path length Min                     1000
exploration/Rewards Mean                          -0.00758745
exploration/Rewards Std                            0.122863
exploration/Rewards Max                            0.401181
exploration/Rewards Min                           -0.416755
exploration/Returns Mean                          -7.58745
exploration/Returns Std                            0
exploration/Returns Max                           -7.58745
exploration/Returns Min                           -7.58745
exploration/Actions Mean                           0.00265349
exploration/Actions Std                            0.101511
exploration/Actions Max                            0.365531
exploration/Actions Min                           -0.426894
exploration/Num Paths                              1
exploration/Average Returns                       -7.58745
exploration/env_infos/final/reward_run Mean        0.0603137
exploration/env_infos/final/reward_run Std         0
exploration/env_infos/final/reward_run Max         0.0603137
exploration/env_infos/final/reward_run Min         0.0603137
exploration/env_infos/initial/reward_run Mean      0.180114
exploration/env_infos/initial/reward_run Std       0
exploration/env_infos/initial/reward_run Max       0.180114
exploration/env_infos/initial/reward_run Min       0.180114
exploration/env_infos/reward_run Mean             -0.00140059
exploration/env_infos/reward_run Std               0.123116
exploration/env_infos/reward_run Max               0.423649
exploration/env_infos/reward_run Min              -0.404612
exploration/env_infos/final/reward_ctrl Mean      -0.00249774
exploration/env_infos/final/reward_ctrl Std        0
exploration/env_infos/final/reward_ctrl Max       -0.00249774
exploration/env_infos/final/reward_ctrl Min       -0.00249774
exploration/env_infos/initial/reward_ctrl Mean    -0.0111408
exploration/env_infos/initial/reward_ctrl Std      0
exploration/env_infos/initial/reward_ctrl Max     -0.0111408
exploration/env_infos/initial/reward_ctrl Min     -0.0111408
exploration/env_infos/reward_ctrl Mean            -0.00618686
exploration/env_infos/reward_ctrl Std              0.00371784
exploration/env_infos/reward_ctrl Max             -0.000337392
exploration/env_infos/reward_ctrl Min             -0.0303957
evaluation/num steps total                      5000
evaluation/num paths total                         5
evaluation/path length Mean                     1000
evaluation/path length Std                         0
evaluation/path length Max                      1000
evaluation/path length Min                      1000
evaluation/Rewards Mean                           -0.00095761
evaluation/Rewards Std                             0.018536
evaluation/Rewards Max                             0.128332
evaluation/Rewards Min                            -0.414749
evaluation/Returns Mean                           -0.95761
evaluation/Returns Std                             0.711838
evaluation/Returns Max                            -0.2637
evaluation/Returns Min                            -1.99403
evaluation/Actions Mean                            0.00268377
evaluation/Actions Std                             0.00506006
evaluation/Actions Max                             0.0105498
evaluation/Actions Min                            -0.00797836
evaluation/Num Paths                               5
evaluation/Average Returns                        -0.95761
evaluation/env_infos/final/reward_run Mean        -4.16334e-17
evaluation/env_infos/final/reward_run Std          8.32667e-17
evaluation/env_infos/final/reward_run Max          0
evaluation/env_infos/final/reward_run Min         -2.08167e-16
evaluation/env_infos/initial/reward_run Mean      -0.12191
evaluation/env_infos/initial/reward_run Std        0.176383
evaluation/env_infos/initial/reward_run Max        0.0442575
evaluation/env_infos/initial/reward_run Min       -0.414728
evaluation/env_infos/reward_run Mean              -0.000937926
evaluation/env_infos/reward_run Std                0.018536
evaluation/env_infos/reward_run Max                0.128353
evaluation/env_infos/reward_run Min               -0.414728
evaluation/env_infos/final/reward_ctrl Mean       -1.96782e-05
evaluation/env_infos/final/reward_ctrl Std         0
evaluation/env_infos/final/reward_ctrl Max        -1.96782e-05
evaluation/env_infos/final/reward_ctrl Min        -1.96782e-05
evaluation/env_infos/initial/reward_ctrl Mean     -1.98402e-05
evaluation/env_infos/initial/reward_ctrl Std       5.40769e-07
evaluation/env_infos/initial/reward_ctrl Max      -1.92955e-05
evaluation/env_infos/initial/reward_ctrl Min      -2.07569e-05
evaluation/env_infos/reward_ctrl Mean             -1.9684e-05
evaluation/env_infos/reward_ctrl Std               2.55165e-07
evaluation/env_infos/reward_ctrl Max              -1.52903e-05
evaluation/env_infos/reward_ctrl Min              -3.24071e-05
time/data storing (s)                              0.00476853
time/evaluation sampling (s)                       0.958573
time/exploration sampling (s)                      0.223239
time/logging (s)                                   0.0158897
time/saving (s)                                    0.00814019
time/training (s)                                 13.4028
time/epoch (s)                                    14.6134
time/total (s)                                    14.9457
Epoch                                              0
----------------------------------------------  --------------
2019-08-15 12:32:51.254490 EDT | [rlkit-post-refactor-td3-half-cheetah_2019_08_15_12_32_20_0000--s-0] Epoch 1 finished
----------------------------------------------  ---------------
replay_buffer/size                               3000
trainer/QF1 Loss                                    0.227328
trainer/QF2 Loss                                    0.23541
trainer/Policy Loss                                -2.00669
trainer/Q1 Predictions Mean                         1.38551
trainer/Q1 Predictions Std                          0.437786
trainer/Q1 Predictions Max                          2.13359
trainer/Q1 Predictions Min                          0.622376
trainer/Q2 Predictions Mean                         1.3888
trainer/Q2 Predictions Std                          0.429912
trainer/Q2 Predictions Max                          2.13136
trainer/Q2 Predictions Min                          0.638434
trainer/Q Targets Mean                              1.13079
trainer/Q Targets Std                               0.821619
trainer/Q Targets Max                               2.23649
trainer/Q Targets Min                              -0.442605
trainer/Bellman Errors 1 Mean                       0.227329
trainer/Bellman Errors 1 Std                        0.337044
trainer/Bellman Errors 1 Max                        1.49316
trainer/Bellman Errors 1 Min                        6.42917e-08
trainer/Bellman Errors 2 Mean                       0.23541
trainer/Bellman Errors 2 Std                        0.348588
trainer/Bellman Errors 2 Max                        1.53643
trainer/Bellman Errors 2 Min                        5.13012e-08
trainer/Policy Action Mean                          1.88282e-07
trainer/Policy Action Std                           0.999999
trainer/Policy Action Max                           1
trainer/Policy Action Min                          -1
exploration/num steps total                      3000
exploration/num paths total                         3
exploration/path length Mean                     1000
exploration/path length Std                         0
exploration/path length Max                      1000
exploration/path length Min                      1000
exploration/Rewards Mean                           -0.553908
exploration/Rewards Std                             0.0735626
exploration/Rewards Max                             0.33339
exploration/Rewards Min                            -0.766393
exploration/Returns Mean                         -553.908
exploration/Returns Std                             0
exploration/Returns Max                          -553.908
exploration/Returns Min                          -553.908
exploration/Actions Mean                            0.000860627
exploration/Actions Std                             0.961286
exploration/Actions Max                             1
exploration/Actions Min                            -1
exploration/Num Paths                               1
exploration/Average Returns                      -553.908
exploration/env_infos/final/reward_run Mean         0.0595467
exploration/env_infos/final/reward_run Std          0
exploration/env_infos/final/reward_run Max          0.0595467
exploration/env_infos/final/reward_run Min          0.0595467
exploration/env_infos/initial/reward_run Mean       0.868499
exploration/env_infos/initial/reward_run Std        0
exploration/env_infos/initial/reward_run Max        0.868499
exploration/env_infos/initial/reward_run Min        0.868499
exploration/env_infos/reward_run Mean               0.000534635
exploration/env_infos/reward_run Std                0.0785966
exploration/env_infos/reward_run Max                0.868499
exploration/env_infos/reward_run Min               -0.247115
exploration/env_infos/final/reward_ctrl Mean       -0.570168
exploration/env_infos/final/reward_ctrl Std         0
exploration/env_infos/final/reward_ctrl Max        -0.570168
exploration/env_infos/final/reward_ctrl Min        -0.570168
exploration/env_infos/initial/reward_ctrl Mean     -0.535109
exploration/env_infos/initial/reward_ctrl Std       0
exploration/env_infos/initial/reward_ctrl Max      -0.535109
exploration/env_infos/initial/reward_ctrl Min      -0.535109
exploration/env_infos/reward_ctrl Mean             -0.554443
exploration/env_infos/reward_ctrl Std               0.0263077
exploration/env_infos/reward_ctrl Max              -0.472867
exploration/env_infos/reward_ctrl Min              -0.6
evaluation/num steps total                      10000
evaluation/num paths total                         10
evaluation/path length Mean                      1000
evaluation/path length Std                          0
evaluation/path length Max                       1000
evaluation/path length Min                       1000
evaluation/Rewards Mean                            -0.59776
evaluation/Rewards Std                              0.0491304
evaluation/Rewards Max                              0.597281
evaluation/Rewards Min                             -0.918474
evaluation/Returns Mean                          -597.76
evaluation/Returns Std                              0.769957
evaluation/Returns Max                           -597.007
evaluation/Returns Min                           -598.872
evaluation/Actions Mean                             2.38601e-07
evaluation/Actions Std                              0.999999
evaluation/Actions Max                              1
evaluation/Actions Min                             -1
evaluation/Num Paths                                5
evaluation/Average Returns                       -597.76
evaluation/env_infos/final/reward_run Mean          1.38778e-16
evaluation/env_infos/final/reward_run Std           2.77556e-16
evaluation/env_infos/final/reward_run Max           6.93889e-16
evaluation/env_infos/final/reward_run Min           0
evaluation/env_infos/initial/reward_run Mean        1.01126
evaluation/env_infos/initial/reward_run Std         0.107721
evaluation/env_infos/initial/reward_run Max         1.19728
evaluation/env_infos/initial/reward_run Min         0.890849
evaluation/env_infos/reward_run Mean                0.00223851
evaluation/env_infos/reward_run Std                 0.0491304
evaluation/env_infos/reward_run Max                 1.19728
evaluation/env_infos/reward_run Min                -0.318474
evaluation/env_infos/final/reward_ctrl Mean        -0.599999
evaluation/env_infos/final/reward_ctrl Std          0
evaluation/env_infos/final/reward_ctrl Max         -0.599999
evaluation/env_infos/final/reward_ctrl Min         -0.599999
evaluation/env_infos/initial/reward_ctrl Mean      -0.599997
evaluation/env_infos/initial/reward_ctrl Std        2.58374e-07
evaluation/env_infos/initial/reward_ctrl Max       -0.599997
evaluation/env_infos/initial/reward_ctrl Min       -0.599998
evaluation/env_infos/reward_ctrl Mean              -0.599999
evaluation/env_infos/reward_ctrl Std                1.14025e-07
evaluation/env_infos/reward_ctrl Max               -0.599996
evaluation/env_infos/reward_ctrl Min               -0.6
time/data storing (s)                               0.00477389
time/evaluation sampling (s)                        0.960813
time/exploration sampling (s)                       0.221486
time/logging (s)                                    0.0158852
time/saving (s)                                     0.00541102
time/training (s)                                  15.0707
time/epoch (s)                                     16.2791
time/total (s)                                     31.2296
Epoch                                               1
----------------------------------------------  ---------------
2019-08-15 12:33:10.500275 EDT | [rlkit-post-refactor-td3-half-cheetah_2019_08_15_12_32_20_0000--s-0] Epoch 2 finished
----------------------------------------------  ---------------
replay_buffer/size                               4000
trainer/QF1 Loss                                    0.0247666
trainer/QF2 Loss                                    0.0252013
trainer/Policy Loss                                 0.116729
trainer/Q1 Predictions Mean                         0.0202809
trainer/Q1 Predictions Std                          1.28602
trainer/Q1 Predictions Max                          1.95698
trainer/Q1 Predictions Min                         -1.58257
trainer/Q2 Predictions Mean                         0.0195033
trainer/Q2 Predictions Std                          1.28338
trainer/Q2 Predictions Max                          1.95061
trainer/Q2 Predictions Min                         -1.58705
trainer/Q Targets Mean                              0.0468257
trainer/Q Targets Std                               1.28243
trainer/Q Targets Max                               2.01264
trainer/Q Targets Min                              -1.68924
trainer/Bellman Errors 1 Mean                       0.0247667
trainer/Bellman Errors 1 Std                        0.0329078
trainer/Bellman Errors 1 Max                        0.253229
trainer/Bellman Errors 1 Min                        8.76824e-09
trainer/Bellman Errors 2 Mean                       0.0252013
trainer/Bellman Errors 2 Std                        0.033883
trainer/Bellman Errors 2 Max                        0.255289
trainer/Bellman Errors 2 Min                        3.92732e-07
trainer/Policy Action Mean                          0.129163
trainer/Policy Action Std                           0.849629
trainer/Policy Action Max                           1
trainer/Policy Action Min                          -1
exploration/num steps total                      4000
exploration/num paths total                         4
exploration/path length Mean                     1000
exploration/path length Std                         0
exploration/path length Max                      1000
exploration/path length Min                      1000
exploration/Rewards Mean                           -0.297104
exploration/Rewards Std                             0.103624
exploration/Rewards Max                             0.288008
exploration/Rewards Min                            -0.606024
exploration/Returns Mean                         -297.104
exploration/Returns Std                             0
exploration/Returns Max                          -297.104
exploration/Returns Min                          -297.104
exploration/Actions Mean                            0.178723
exploration/Actions Std                             0.772731
exploration/Actions Max                             1
exploration/Actions Min                            -1
exploration/Num Paths                               1
exploration/Average Returns                      -297.104
exploration/env_infos/final/reward_run Mean         0.165066
exploration/env_infos/final/reward_run Std          0
exploration/env_infos/final/reward_run Max          0.165066
exploration/env_infos/final/reward_run Min          0.165066
exploration/env_infos/initial/reward_run Mean       0.801142
exploration/env_infos/initial/reward_run Std        0
exploration/env_infos/initial/reward_run Max        0.801142
exploration/env_infos/initial/reward_run Min        0.801142
exploration/env_infos/reward_run Mean               0.0803292
exploration/env_infos/reward_run Std                0.100752
exploration/env_infos/reward_run Max                0.801142
exploration/env_infos/reward_run Min               -0.23338
exploration/env_infos/final/reward_ctrl Mean       -0.384188
exploration/env_infos/final/reward_ctrl Std         0
exploration/env_infos/final/reward_ctrl Max        -0.384188
exploration/env_infos/final/reward_ctrl Min        -0.384188
exploration/env_infos/initial/reward_ctrl Mean     -0.513134
exploration/env_infos/initial/reward_ctrl Std       0
exploration/env_infos/initial/reward_ctrl Max      -0.513134
exploration/env_infos/initial/reward_ctrl Min      -0.513134
exploration/env_infos/reward_ctrl Mean             -0.377433
exploration/env_infos/reward_ctrl Std               0.0777233
exploration/env_infos/reward_ctrl Max              -0.142462
exploration/env_infos/reward_ctrl Min              -0.583936
evaluation/num steps total                      15000
evaluation/num paths total                         15
evaluation/path length Mean                      1000
evaluation/path length Std                          0
evaluation/path length Max                       1000
evaluation/path length Min                       1000
evaluation/Rewards Mean                            -0.195888
evaluation/Rewards Std                              0.11537
evaluation/Rewards Max                              0.769596
evaluation/Rewards Min                             -0.888824
evaluation/Returns Mean                          -195.888
evaluation/Returns Std                              4.58316
evaluation/Returns Max                           -189.094
evaluation/Returns Min                           -202.091
evaluation/Actions Mean                             0.176073
evaluation/Actions Std                              0.775281
evaluation/Actions Max                              1
evaluation/Actions Min                             -0.999882
evaluation/Num Paths                                5
evaluation/Average Returns                       -195.888
evaluation/env_infos/final/reward_run Mean          0.155328
evaluation/env_infos/final/reward_run Std           0.103976
evaluation/env_infos/final/reward_run Max           0.299055
evaluation/env_infos/final/reward_run Min           0.0514845
evaluation/env_infos/initial/reward_run Mean        0.973681
evaluation/env_infos/initial/reward_run Std         0.137272
evaluation/env_infos/initial/reward_run Max         1.21714
evaluation/env_infos/initial/reward_run Min         0.799967
evaluation/env_infos/reward_run Mean                0.18335
evaluation/env_infos/reward_run Std                 0.118835
evaluation/env_infos/reward_run Max                 1.30439
evaluation/env_infos/reward_run Min                -0.526929
evaluation/env_infos/final/reward_ctrl Mean        -0.291452
evaluation/env_infos/final/reward_ctrl Std          0.0646053
evaluation/env_infos/final/reward_ctrl Max         -0.19945
evaluation/env_infos/final/reward_ctrl Min         -0.353087
evaluation/env_infos/initial/reward_ctrl Mean      -0.539102
evaluation/env_infos/initial/reward_ctrl Std        0.00298739
evaluation/env_infos/initial/reward_ctrl Max       -0.535654
evaluation/env_infos/initial/reward_ctrl Min       -0.543248
evaluation/env_infos/reward_ctrl Mean              -0.379238
evaluation/env_infos/reward_ctrl Std                0.116803
evaluation/env_infos/reward_ctrl Max               -0.196261
evaluation/env_infos/reward_ctrl Min               -0.562971
time/data storing (s)                               0.00480148
time/evaluation sampling (s)                        0.974377
time/exploration sampling (s)                       0.222567
time/logging (s)                                    0.01586
time/saving (s)                                     0.00533491
time/training (s)                                  18.0177
time/epoch (s)                                     19.2407
time/total (s)                                     50.4749
Epoch                                               2
----------------------------------------------  ---------------
