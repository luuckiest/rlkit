2019-08-15 12:27:15.714652 EDT | [name-of-experiment_2019_08_15_12_27_02_0000--s-0] Epoch 0 finished
----------------------------------------------  --------------
replay_buffer/size                              2000
trainer/QF1 Loss                                  12.9249
trainer/QF2 Loss                                  12.9981
trainer/Policy Loss                               -4.0009
trainer/Q1 Predictions Mean                        0.0170906
trainer/Q1 Predictions Std                         0.00458479
trainer/Q1 Predictions Max                         0.0345907
trainer/Q1 Predictions Min                         0.00856152
trainer/Q2 Predictions Mean                        0.0063918
trainer/Q2 Predictions Std                         0.0057613
trainer/Q2 Predictions Max                         0.0213856
trainer/Q2 Predictions Min                        -0.00790261
trainer/Q Targets Mean                             3.5101
trainer/Q Targets Std                              0.850835
trainer/Q Targets Max                              6.28049
trainer/Q Targets Min                              0.197983
trainer/Log Pis Mean                              -3.99462
trainer/Log Pis Std                                0.513784
trainer/Log Pis Max                               -2.56223
trainer/Log Pis Min                               -5.20741
trainer/Policy mu Mean                            -0.000405568
trainer/Policy mu Std                              0.00247474
trainer/Policy mu Max                              0.0057771
trainer/Policy mu Min                             -0.00818509
trainer/Policy log std Mean                        0.00125909
trainer/Policy log std Std                         0.00203489
trainer/Policy log std Max                         0.0084578
trainer/Policy log std Min                        -0.00610533
trainer/Alpha                                      0.9997
trainer/Alpha Loss                                -0
exploration/num steps total                     2000
exploration/num paths total                        2
exploration/path length Mean                    1000
exploration/path length Std                        0
exploration/path length Max                     1000
exploration/path length Min                     1000
exploration/Rewards Mean                          -0.473998
exploration/Rewards Std                            0.694676
exploration/Rewards Max                            1.43127
exploration/Rewards Min                           -2.44144
exploration/Returns Mean                        -473.998
exploration/Returns Std                            0
exploration/Returns Max                         -473.998
exploration/Returns Min                         -473.998
exploration/Actions Mean                          -0.00386213
exploration/Actions Std                            0.62978
exploration/Actions Max                            0.998398
exploration/Actions Min                           -0.998847
exploration/Num Paths                              1
exploration/Average Returns                     -473.998
exploration/env_infos/final/reward_run Mean       -0.0751109
exploration/env_infos/final/reward_run Std         0
exploration/env_infos/final/reward_run Max        -0.0751109
exploration/env_infos/final/reward_run Min        -0.0751109
exploration/env_infos/initial/reward_run Mean     -0.211935
exploration/env_infos/initial/reward_run Std       0
exploration/env_infos/initial/reward_run Max      -0.211935
exploration/env_infos/initial/reward_run Min      -0.211935
exploration/env_infos/reward_run Mean             -0.236015
exploration/env_infos/reward_run Std               0.690404
exploration/env_infos/reward_run Max               1.69625
exploration/env_infos/reward_run Min              -2.17481
exploration/env_infos/final/reward_ctrl Mean      -0.247864
exploration/env_infos/final/reward_ctrl Std        0
exploration/env_infos/final/reward_ctrl Max       -0.247864
exploration/env_infos/final/reward_ctrl Min       -0.247864
exploration/env_infos/initial/reward_ctrl Mean    -0.276624
exploration/env_infos/initial/reward_ctrl Std      0
exploration/env_infos/initial/reward_ctrl Max     -0.276624
exploration/env_infos/initial/reward_ctrl Min     -0.276624
exploration/env_infos/reward_ctrl Mean            -0.237983
exploration/env_infos/reward_ctrl Std              0.0758063
exploration/env_infos/reward_ctrl Max             -0.0193843
exploration/env_infos/reward_ctrl Min             -0.496714
evaluation/num steps total                      5000
evaluation/num paths total                         5
evaluation/path length Mean                     1000
evaluation/path length Std                         0
evaluation/path length Max                      1000
evaluation/path length Min                      1000
evaluation/Rewards Mean                            0.00035564
evaluation/Rewards Std                             0.0191961
evaluation/Rewards Max                             0.414803
evaluation/Rewards Min                            -0.334565
evaluation/Returns Mean                            0.35564
evaluation/Returns Std                             0.929932
evaluation/Returns Max                             1.60334
evaluation/Returns Min                            -0.82073
evaluation/Actions Mean                           -0.000150723
evaluation/Actions Std                             0.00120942
evaluation/Actions Max                             0.00351013
evaluation/Actions Min                            -0.00371201
evaluation/Num Paths                               5
evaluation/Average Returns                         0.35564
evaluation/env_infos/final/reward_run Mean         7.97973e-17
evaluation/env_infos/final/reward_run Std          1.09494e-16
evaluation/env_infos/final/reward_run Max          2.77556e-16
evaluation/env_infos/final/reward_run Min          0
evaluation/env_infos/initial/reward_run Mean       0.168503
evaluation/env_infos/initial/reward_run Std        0.13185
evaluation/env_infos/initial/reward_run Max        0.381839
evaluation/env_infos/initial/reward_run Min        0.042485
evaluation/env_infos/reward_run Mean               0.000356531
evaluation/env_infos/reward_run Std                0.0191961
evaluation/env_infos/reward_run Max                0.414804
evaluation/env_infos/reward_run Min               -0.334565
evaluation/env_infos/final/reward_ctrl Mean       -8.89548e-07
evaluation/env_infos/final/reward_ctrl Std         0
evaluation/env_infos/final/reward_ctrl Max        -8.89548e-07
evaluation/env_infos/final/reward_ctrl Min        -8.89548e-07
evaluation/env_infos/initial/reward_ctrl Mean     -8.56669e-07
evaluation/env_infos/initial/reward_ctrl Std       3.85194e-08
evaluation/env_infos/initial/reward_ctrl Max      -8.00473e-07
evaluation/env_infos/initial/reward_ctrl Min      -9.18037e-07
evaluation/env_infos/reward_ctrl Mean             -8.91234e-07
evaluation/env_infos/reward_ctrl Std               4.01007e-08
evaluation/env_infos/reward_ctrl Max              -7.35171e-07
evaluation/env_infos/reward_ctrl Min              -3.09758e-06
time/data storing (s)                              0.00482983
time/evaluation sampling (s)                       1.12309
time/exploration sampling (s)                      0.312092
time/logging (s)                                   0.0152102
time/saving (s)                                    0.00785192
time/training (s)                                 11.3089
time/epoch (s)                                    12.772
time/total (s)                                    13.21
Epoch                                              0
----------------------------------------------  --------------
