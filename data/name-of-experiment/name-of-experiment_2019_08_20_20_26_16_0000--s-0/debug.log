2019-08-20 20:26:25.604816 EDT | [name-of-experiment_2019_08_20_20_26_16_0000--s-0] Epoch 0 finished
----------------------------------------------  ---------------
replay_buffer/size                              11000
trainer/QF Loss                                     0.186231
trainer/Policy Loss                                 0.00691504
trainer/Raw Policy Loss                             0.00691504
trainer/Preactivation Policy Loss                   0
trainer/Q Predictions Mean                         -0.00691043
trainer/Q Predictions Std                           0.00248435
trainer/Q Predictions Max                          -0.000867844
trainer/Q Predictions Min                          -0.014749
trainer/Q Targets Mean                             -0.20107
trainer/Q Targets Std                               0.384973
trainer/Q Targets Max                               0.800413
trainer/Q Targets Min                              -1.25353
trainer/Bellman Errors Mean                         0.186231
trainer/Bellman Errors Std                          0.300571
trainer/Bellman Errors Max                          1.55388
trainer/Bellman Errors Min                          4.9966e-06
trainer/Policy Action Mean                          0.00247665
trainer/Policy Action Std                           0.0059129
trainer/Policy Action Max                           0.0180684
trainer/Policy Action Min                          -0.0135509
exploration/num steps total                     11000
exploration/num paths total                        11
exploration/path length Mean                     1000
exploration/path length Std                         0
exploration/path length Max                      1000
exploration/path length Min                      1000
exploration/Rewards Mean                           -0.187694
exploration/Rewards Std                             0.468746
exploration/Rewards Max                             1.34795
exploration/Rewards Min                            -1.90207
exploration/Returns Mean                         -187.694
exploration/Returns Std                             0
exploration/Returns Max                          -187.694
exploration/Returns Min                          -187.694
exploration/Actions Mean                            0.00314923
exploration/Actions Std                             0.532014
exploration/Actions Max                             1
exploration/Actions Min                            -1
exploration/Num Paths                               1
exploration/Average Returns                      -187.694
exploration/env_infos/final/reward_run Mean         0.203935
exploration/env_infos/final/reward_run Std          0
exploration/env_infos/final/reward_run Max          0.203935
exploration/env_infos/final/reward_run Min          0.203935
exploration/env_infos/initial/reward_run Mean       0.188608
exploration/env_infos/initial/reward_run Std        0
exploration/env_infos/initial/reward_run Max        0.188608
exploration/env_infos/initial/reward_run Min        0.188608
exploration/env_infos/reward_run Mean              -0.0178641
exploration/env_infos/reward_run Std                0.470143
exploration/env_infos/reward_run Max                1.54195
exploration/env_infos/reward_run Min               -1.69266
exploration/env_infos/final/reward_ctrl Mean       -0.290842
exploration/env_infos/final/reward_ctrl Std         0
exploration/env_infos/final/reward_ctrl Max        -0.290842
exploration/env_infos/final/reward_ctrl Min        -0.290842
exploration/env_infos/initial/reward_ctrl Mean     -0.0186933
exploration/env_infos/initial/reward_ctrl Std       0
exploration/env_infos/initial/reward_ctrl Max      -0.0186933
exploration/env_infos/initial/reward_ctrl Min      -0.0186933
exploration/env_infos/reward_ctrl Mean             -0.16983
exploration/env_infos/reward_ctrl Std               0.0741603
exploration/env_infos/reward_ctrl Max              -0.0186933
exploration/env_infos/reward_ctrl Min              -0.423108
evaluation/num steps total                       1000
evaluation/num paths total                          1
evaluation/path length Mean                      1000
evaluation/path length Std                          0
evaluation/path length Max                       1000
evaluation/path length Min                       1000
evaluation/Rewards Mean                            -0.000516654
evaluation/Rewards Std                              0.0106101
evaluation/Rewards Max                              0.0424346
evaluation/Rewards Min                             -0.166791
evaluation/Returns Mean                            -0.516654
evaluation/Returns Std                              0
evaluation/Returns Max                             -0.516654
evaluation/Returns Min                             -0.516654
evaluation/Actions Mean                             0.00216853
evaluation/Actions Std                              0.00446746
evaluation/Actions Max                              0.00829892
evaluation/Actions Min                             -0.0083529
evaluation/Num Paths                                1
evaluation/Average Returns                         -0.516654
evaluation/env_infos/final/reward_run Mean          0
evaluation/env_infos/final/reward_run Std           0
evaluation/env_infos/final/reward_run Max           0
evaluation/env_infos/final/reward_run Min           0
evaluation/env_infos/initial/reward_run Mean        0.0372725
evaluation/env_infos/initial/reward_run Std         0
evaluation/env_infos/initial/reward_run Max         0.0372725
evaluation/env_infos/initial/reward_run Min         0.0372725
evaluation/env_infos/reward_run Mean               -0.000501857
evaluation/env_infos/reward_run Std                 0.0106101
evaluation/env_infos/reward_run Max                 0.0424488
evaluation/env_infos/reward_run Min                -0.166776
evaluation/env_infos/final/reward_ctrl Mean        -1.47961e-05
evaluation/env_infos/final/reward_ctrl Std          0
evaluation/env_infos/final/reward_ctrl Max         -1.47961e-05
evaluation/env_infos/final/reward_ctrl Min         -1.47961e-05
evaluation/env_infos/initial/reward_ctrl Mean      -1.45336e-05
evaluation/env_infos/initial/reward_ctrl Std        0
evaluation/env_infos/initial/reward_ctrl Max       -1.45336e-05
evaluation/env_infos/initial/reward_ctrl Min       -1.45336e-05
evaluation/env_infos/reward_ctrl Mean              -1.47963e-05
evaluation/env_infos/reward_ctrl Std                1.87738e-07
evaluation/env_infos/reward_ctrl Max               -1.40261e-05
evaluation/env_infos/reward_ctrl Min               -2.00196e-05
time/data storing (s)                               0.00390287
time/evaluation sampling (s)                        0.199575
time/exploration sampling (s)                       0.221214
time/logging (s)                                    0.0059496
time/saving (s)                                     0.00653114
time/training (s)                                   5.89976
time/epoch (s)                                      6.33693
time/total (s)                                      8.71441
Epoch                                               0
----------------------------------------------  ---------------
