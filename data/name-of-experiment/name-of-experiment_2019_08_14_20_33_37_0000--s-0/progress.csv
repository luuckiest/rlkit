evaluation/env_infos/initial/reward_ctrl Max,exploration/path length Min,exploration/Rewards Mean,exploration/env_infos/reward_ctrl Std,trainer/Bellman Errors Min,time/exploration sampling (s),trainer/Policy Action Std,trainer/Bellman Errors Mean,time/saving (s),time/data storing (s),exploration/Rewards Min,time/total (s),exploration/path length Max,exploration/env_infos/reward_ctrl Mean,exploration/env_infos/initial/reward_ctrl Mean,exploration/Returns Mean,exploration/Actions Mean,evaluation/num paths total,evaluation/path length Max,exploration/env_infos/initial/reward_run Min,exploration/env_infos/initial/reward_ctrl Min,evaluation/Num Paths,evaluation/env_infos/reward_ctrl Mean,evaluation/env_infos/initial/reward_ctrl Mean,evaluation/env_infos/initial/reward_run Min,exploration/env_infos/initial/reward_run Max,exploration/path length Mean,trainer/Q Targets Std,exploration/Actions Std,exploration/env_infos/initial/reward_run Mean,evaluation/env_infos/final/reward_run Std,exploration/Average Returns,evaluation/Actions Max,evaluation/Actions Std,evaluation/env_infos/initial/reward_run Max,evaluation/Returns Std,trainer/Q Predictions Mean,evaluation/env_infos/final/reward_ctrl Min,exploration/env_infos/initial/reward_ctrl Max,trainer/Q Targets Mean,trainer/QF Loss,trainer/Bellman Errors Std,evaluation/env_infos/reward_ctrl Min,exploration/path length Std,exploration/Rewards Max,evaluation/env_infos/initial/reward_ctrl Min,evaluation/num steps total,evaluation/env_infos/reward_run Std,trainer/Preactivation Policy Loss,time/logging (s),exploration/Returns Max,evaluation/env_infos/final/reward_ctrl Mean,time/epoch (s),evaluation/Rewards Mean,time/evaluation sampling (s),exploration/Actions Min,evaluation/Returns Mean,trainer/Q Predictions Max,evaluation/env_infos/final/reward_run Max,exploration/env_infos/reward_run Mean,trainer/Q Predictions Min,evaluation/env_infos/final/reward_run Min,trainer/Q Targets Min,exploration/Returns Min,evaluation/env_infos/final/reward_run Mean,evaluation/Actions Mean,exploration/env_infos/final/reward_run Min,exploration/env_infos/reward_ctrl Max,replay_buffer/size,exploration/num paths total,exploration/env_infos/initial/reward_run Std,exploration/env_infos/reward_ctrl Min,exploration/env_infos/final/reward_run Mean,exploration/env_infos/final/reward_ctrl Mean,exploration/Num Paths,evaluation/env_infos/reward_run Min,exploration/env_infos/final/reward_ctrl Std,trainer/Policy Action Max,evaluation/env_infos/final/reward_ctrl Max,time/training (s),trainer/Policy Loss,Epoch,evaluation/Rewards Min,trainer/Q Targets Max,exploration/env_infos/final/reward_run Std,evaluation/env_infos/final/reward_ctrl Std,evaluation/Returns Max,exploration/env_infos/initial/reward_ctrl Std,trainer/Q Predictions Std,evaluation/path length Mean,exploration/env_infos/final/reward_ctrl Max,evaluation/env_infos/reward_run Mean,evaluation/env_infos/initial/reward_run Std,exploration/env_infos/reward_run Std,evaluation/env_infos/reward_ctrl Std,exploration/env_infos/reward_run Min,exploration/Actions Max,exploration/num steps total,evaluation/path length Std,evaluation/env_infos/initial/reward_run Mean,evaluation/env_infos/initial/reward_ctrl Std,exploration/Returns Std,trainer/Policy Action Mean,evaluation/Returns Min,evaluation/Actions Min,exploration/env_infos/final/reward_run Max,trainer/Raw Policy Loss,evaluation/Rewards Max,trainer/Bellman Errors Max,evaluation/Average Returns,exploration/env_infos/reward_run Max,evaluation/path length Min,exploration/env_infos/final/reward_ctrl Min,trainer/Policy Action Min,evaluation/Rewards Std,evaluation/env_infos/reward_run Max,evaluation/env_infos/reward_ctrl Max,exploration/Rewards Std
-7.40363902878e-06,1000,-0.187988522148,0.0786644133533,6.53866e-08,0.18358415000147943,0.00562949,0.126999,0.006281967998802429,0.004294716000003973,-1.74268337724,10.372492472999511,1000,-0.163946918552,-0.0111182264555,-187.988522148,-0.0115541672518,1,1000,-0.0846647337444,-0.0111182264555,1,-7.76264831438e-06,-7.40363902878e-06,-0.185893376857,-0.0846647337444,1000.0,0.336642,0.522600579288,-0.0846647337444,0.0,-187.988522148,0.00502367,0.00355742,-0.185893376857,0.0,-0.000277031,-7.75830994826e-06,-0.0111182264555,-0.117506,0.126999,0.202729,-1.1404651741e-05,0.0,0.899326632971,-7.40363902878e-06,1000,0.0184050602492,0.0,0.0056338779995712684,-187.988522148,-7.75830994826e-06,8.447573017998366,-0.00113596035133,0.16651690499929828,-1.0,-1.13596035133,0.00943436,2.77555756156e-16,-0.0240416035961,-0.00754132,2.77555756156e-16,-1.14285,-187.988522148,2.77555756156e-16,0.00053146,-0.7278845899,-0.0111182264555,11000,11,0.0,-0.460584287859,-0.7278845899,-0.283541619091,1,-0.276426932381,0.0,0.0152813,-7.75830994826e-06,8.08126140099921,0.000309271,0,-0.276438337033,0.841237,0.0,0.0,-1.13596035133,0.0,0.00327882,1000.0,-0.283541619091,-0.00112819770302,0.0,0.439617368677,1.25253956819e-07,-1.37663477691,1.0,11000,0.0,-0.185893376857,0.0,0.0,0.000541498,-1.13596035133,-0.00694363,-0.7278845899,0.000309271,0.0756722500665,1.29378,-1.13596035133,1.05542446452,1000,-0.283541619091,-0.0162727,0.0184051265963,0.0756802051256,-7.06532518961e-06,0.44705909397
-0.0959792613983,1000,-0.0827192439536,0.0894259175698,3.98863e-07,0.18122530600157916,0.513351,0.0988093,0.003414336999412626,0.004329883000536938,-1.15397285715,19.299576791003346,1000,-0.234365853614,-0.220550996612,-82.7192439536,-0.0464825785334,2,1000,0.248046906002,-0.220550996612,1,-0.150358051169,-0.0959792613983,0.41627785888,0.248046906002,1000.0,2.30068,0.62325686993,0.248046906002,0.0,-82.7192439536,0.956493,0.407811,0.41627785888,0.0,0.687403,-0.148235535622,-0.220550996612,0.639853,0.0988093,0.282709,-0.234957528114,0.0,1.8752827055,-0.0959792613983,2000,0.0355345323208,0.0,0.006270535999647109,-82.7192439536,-0.148235535622,8.923625168001308,-0.149213014361,0.16576085100132332,-1.0,-149.213014361,6.52361,-3.79452269605e-08,0.15164660966,-3.40009,-3.79452269605e-08,-4.38203,-82.7192439536,-3.79452269605e-08,0.290322,0.149881538036,-0.0341509799615,12000,12,0.0,-0.560223097705,0.149881538036,-0.0812487399543,1,-0.328354638377,0.0,0.99467,-0.148235535622,8.56262425499881,-0.978704,1,-0.509901004592,6.70046,0.0,0.0,-149.213014361,0.0,2.27017,1000.0,-0.0812487399543,0.00114503680772,0.0,0.374944561456,0.00833965022963,-0.80798551003,1.0,12000,0.0,0.41627785888,0.0,0.0,-0.0584351,-149.213014361,-0.760223,0.149881538036,-0.978704,0.533201912041,2.0782,-149.213014361,2.05927455534,1000,-0.0812487399543,-0.989384,0.0358967861779,0.753966096039,-0.0959792613983,0.37945273645
